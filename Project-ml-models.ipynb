{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master('local[*]') \\\n",
    "        .appName('first_spark_application') \\\n",
    "        .getOrCreate() #if there is a active session it will get or create one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cars = spark.read.csv(\"cars.csv\", header=True, inferSchema=True, nullValue='NA')\n",
    "\n",
    "health = spark.read.csv('./data/train.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing categorical data\n",
    "indexer1 = StringIndexer(inputCol='Vehicle_Age',\n",
    "outputCol='Vehicle_Age_idx')\n",
    "\n",
    "indexer2 = StringIndexer(inputCol='Gender',\n",
    "outputCol='Gender_idx')\n",
    "\n",
    "indexer3 = StringIndexer(inputCol='Vehicle_Damage',\n",
    "outputCol='Vehicle_Damage_idx')\n",
    "\n",
    "\n",
    "# now we need to combine all the features in a single list\n",
    "# we are doing this because pyspark.ml what all the features in a list\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['Age', 'Driving_License', \n",
    "                                       'Region_Code', 'Previously_Insured', \n",
    "                                       'Annual_Premium', \n",
    "                                       'Policy_Sales_Channel', 'Vintage', \n",
    "                                       'Vehicle_Age_idx', 'Gender_idx','Vehicle_Damage_idx'],\n",
    "                            outputCol='features')\n",
    "\n",
    "pipeline = Pipeline(stages=[indexer1, indexer2, indexer3, assembler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthe = pipeline.fit(health).transform(health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+---------------+-----------+------------------+-----------+--------------+--------------+--------------------+-------+--------+---------------+----------+------------------+--------------------+\n",
      "| id|Gender|Age|Driving_License|Region_Code|Previously_Insured|Vehicle_Age|Vehicle_Damage|Annual_Premium|Policy_Sales_Channel|Vintage|Response|Vehicle_Age_idx|Gender_idx|Vehicle_Damage_idx|            features|\n",
      "+---+------+---+---------------+-----------+------------------+-----------+--------------+--------------+--------------------+-------+--------+---------------+----------+------------------+--------------------+\n",
      "|  1|  Male| 44|              1|       28.0|                 0|  > 2 Years|           Yes|       40454.0|                26.0|    217|       1|            2.0|       0.0|               0.0|[44.0,1.0,28.0,0....|\n",
      "|  2|  Male| 76|              1|        3.0|                 0|   1-2 Year|            No|       33536.0|                26.0|    183|       0|            0.0|       0.0|               1.0|[76.0,1.0,3.0,0.0...|\n",
      "+---+------+---+---------------+-----------+------------------+-----------+--------------+--------------+--------------------+-------+--------+---------------+----------+------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "healthe.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preparing data for model fitting\n",
    "\n",
    "- We are selecting the features column and response column to get that data needed for predictions\n",
    "\n",
    "- we need to change the output column name to label for the models to work right in spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_ml = healthe.select(['features','Response']).withColumnRenamed('Response', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[44.0,1.0,28.0,0....|    1|\n",
      "|[76.0,1.0,3.0,0.0...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "health_ml.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a seed for reproducibility\n",
    "# we are spliting the data in test train\n",
    "\n",
    "health_train, health_test = health_ml.randomSplit([0.8, 0.2], seed= 23 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304788 76321\n"
     ]
    }
   ],
   "source": [
    "print(health_train.count(), health_test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(featuresCol='features', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = model.fit(health_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predection = logistic.transform(health_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(10,[0,1,4,5,6],[...|    0|[0.99842955888785...|[0.73074969914917...|       0.0|\n",
      "|(10,[0,1,4,5,6],[...|    0|[0.72326996663944...|[0.67332667918291...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predection.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7703586309135694"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "evaluator.evaluate(predection, {evaluator.metricName: 'weightedPrecision'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
